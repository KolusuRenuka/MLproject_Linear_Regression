{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "ae20364c4a40fbf76faa55d22b75aea653d988f364eee682a5521dc19fa44561"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Linear Regression with Scikit Learn \n",
    "\n",
    "\n",
    "![](https://i.imgur.com/1EzyZvj.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"darkgrid\")\n",
    "matplotlib.rcParams[\"font.size\"] = 14\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (10,6)\n",
    "matplotlib.rcParams[\"figure.facecolor\"] = \"#00000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data from the file insurance.csv into Pandas Dataframe\n",
    "medical_df = pd.read_csv(\"insurance.csv\")\n",
    "medical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyzing the data\n",
    "medical_df.info()\n",
    "# does not contain any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_df.describe()"
   ]
  },
  {
   "source": [
    "# Correlation between the columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation between the columns\n",
    "medical_df.corr()\n",
    "# shows the correlation only between the numeric columns but not the categorical cloumns\n",
    "# change the categorical data into 1s and 0s using one-hot encoding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(medical_df.corr(),cmap =\"Reds\",annot=True)\n",
    "plt.title(\"Correlation Matrix\");"
   ]
  },
  {
   "source": [
    "Input  data and Target data coulmns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the  input data into numeric columns and categorical columns\n",
    "input_cols = medical_df.columns[0:6]\n",
    "inputs_df=  medical_df[input_cols].copy()\n",
    "inputs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = medical_df.columns[6:]\n",
    "target_df = medical_df[target_cols]\n",
    "target_df"
   ]
  },
  {
   "source": [
    "Splitting the input data columns into numeric and categorical data columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = inputs_df.select_dtypes(include = [\"int64\",\"float64\"]).columns.tolist()\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_cols=inputs_df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "cat_cols = [\"region\"]\n",
    "\n",
    "print(cat_cols)\n",
    "#smoker column\n",
    "smokervalue = {\"no\": 0, \"yes\":1}\n",
    "smoker_numeric = inputs_df.smoker.map(smokervalue )\n",
    "\n",
    "print()\n",
    "\n",
    "#sex column\n",
    "sex_values={ \"female\":1,\"male\":0}\n",
    "sex_numeric = inputs_df.sex.map(sex_values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the categorical columns\n",
    "inputs_df[cat_cols].nunique()\n"
   ]
  },
  {
   "source": [
    "Encoding the categorical columns into 1s and 0s using One-Hot encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False,handle_unknown=\"ignore\")\n",
    "encoder.fit(inputs_df[cat_cols])\n",
    "encoded_cols = list(encoder.get_feature_names(cat_cols))\n",
    "inputs_df[encoded_cols] = encoder.transform(inputs_df[cat_cols])\n",
    "inputs_df[\"sex_numeric\"]=sex_numeric\n",
    "inputs_df[\"smoker_numeric\"]= smoker_numeric\n",
    "encoded_cols = ['region_northeast','region_northwest','region_southeast','region_southwest','sex_numeric','smoker_numeric']\n",
    "print(encoded_cols)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the numeric columns to range(0,1)\n",
    "inputs_df[numeric_cols].describe().loc[['min', 'max']]"
   ]
  },
  {
   "source": [
    "Scaling the numeric column data into the range(0,1) so that different ranges of numeric data cannot interrupt the output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using MinMaxScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(inputs_df[numeric_cols])\n",
    "inputs_df[numeric_cols] = scaler.transform(inputs_df[numeric_cols])\n",
    "inputs_df\n"
   ]
  },
  {
   "source": [
    "complete input data has been set to the range(0,1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Splitting the input and target data into test and train sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, test_inputs,train_targets,test_targets = train_test_split(inputs_df[numeric_cols + encoded_cols],target_df, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "generate and train the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(train_inputs,train_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train_inputs)\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets[0:10]"
   ]
  },
  {
   "source": [
    "computing the loss using ROOT MEAN SQUARED ERROR method"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root Mean Squared Error\n",
    "def rmse(target_data,predicted_data):\n",
    "    return np.sqrt(np.mean(np.square(target_data-predicted_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = rmse(train_targets,predictions)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame({\n",
    "    \"features\" : np.append(train_inputs.columns,1),\n",
    "    \"weights\":np.append(model.coef_,model.intercept_)\n",
    "})\n",
    "weights_df"
   ]
  },
  {
   "source": [
    "predicting using test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_inputs)\n",
    "test_predictions[0:10]"
   ]
  },
  {
   "source": [
    "loss1 = rmse(test_targets,test_predictions)\n",
    "loss1"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_predictor = {\n",
    "    'model': model,\n",
    "    \n",
    "    'scaler': scaler,\n",
    "    'encoder': encoder,\n",
    "    'input_cols': input_cols,\n",
    "    'target_cols': target_cols,\n",
    "    'numeric_cols': numeric_cols,\n",
    "    'cat_cols': cat_cols,\n",
    "    'encoded_cols': encoded_cols\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(insurance_predictor,\"insurance_predictor.joblib\")"
   ]
  },
  {
   "source": [
    "predict using new data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_customers = [[28,30,2,1,0,0,1,0,0,0,0]]\n",
    "scaler.transform([[28,30,2]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[0.2173913 , 0.37772397, 0.4,1,0,0,0,1,0]])\n"
   ]
  },
  {
   "source": [
    "## Can use the model by importing  joblib  without retraining "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = joblib.load(\"insurance_predictor.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=new[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k.predict([[0.2173913 , 0.37772397, 0.4,1,0,0,0,1,0]])"
   ]
  }
 ]
}